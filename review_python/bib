%!TEX program = xelatex
% 完整编译: xelatex -> biber/bibtex -> xelatex -> xelatex
\documentclass[lang=cn,a4paper,bibend=bibtex,citestyle=gb7714-2015,bibstyle=gb7714-2015]{elegantpaper}
\usepackage{xeCJK}

% \ExecuteBibliographyOptions{sorting=gb7714-2015} % 引用排序，详见 https://blog.csdn.net/xovee/article/details/109894721#:~:text=year-,%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E6%8E%92%E5%BA%8F%E9%80%89%E9%A1%B9,-%E9%80%89%E9%A1%B9

\title{Large Pre-trained Model-Empowered Data Analysis:\\ A Systematic Review} % 标题
% \author{作者1 \\ 某某大学/机构 \and 作者2 \\ 某某大学/机构} % 作者
% \institute{} % 机构

% \version{} % 版本，可不写（删去本行）

% \date{\zhdate{2022/12/31}} % 日期

% 本文档命令
\usepackage{array}
\usepackage{float} % 使图片表格支持精确位置
% \setCJKmainfont{SimSun} 
\newcommand{\ccr}[1]{\makecell{{\color{#1}\rule{1cm}{1cm}}}}
\addbibresource[location=local]{reference.bib} % 参考文献，不要删除

\begin{document}

\maketitle

\begin{abstract} % 摘要

Data analysis, as a crucial branch of data science, focuses on harnessing advanced mathematical statistics, programming, and machine learning techniques to extract valuable insights from vast datasets. An increasing volume and variety of research has emerged, addressing datasets of diverse modalities, formats, scales, and resolutions across various industries. However, experienced data analysts and software engineers often find themselves overwhelmed by the sheer volume of intricate details involved in ad-hoc solutions, which makes these methods difficult to maintain and scale to more complex systems. To mitigate these burdens, several application domains have introduced large pretrained models (LPMs) into data analysis, combining neural and symbolic inference and leveraging statistical and algebraic principles to automate and enhance the intellectualization of the analysis process. This paper provides a comprehensive review of systematic approaches to optimizing data analysis through the power of LPMs, while critically identifying the limitations of LPMs, to establish a roadmap for their future application in data analysis.

	
	\keywords{data analysis, large pre-trained models, domain-specific languages, analytical interfaces} % 关键词
\end{abstract}

\section{Introduction} % 章节

%\subsection{Status and Needs of Data Analysis} % 子章节

Data analysis aims to identify and understand objects, their evolution trend, and relationships between them~\cite{3Wmodel,nisbet2009handbook}, providing insights for complex systems and promoting the ability to solve real-world problems. The scope of data analysis branches from pattern mining, and retrieval to prediction and causal inference~\cite{pearl2018book}. Data analysis serves as the cornerstone for finding linkage between diverse phenomena and principles, mechanisms, or causes, leveraging this reasoning ability, driving informed decision-making across diverse domains~\cite{provost2013data}. By uncovering hidden patterns, trends, and correlations, data analysis enables organizations to anticipate market shifts, optimize operations, and tailor services to meet evolving human needs. Moreover, in scientific research, data analysis facilitates the validation of hypotheses, the discovery of new phenomena, and the advancement of knowledge by providing empirical evidence to support theoretical models.  

\subsection{Challenges in the Systematic Optimization of Data Analysis}

Data analysis techniques originate from multiple application fields. Though loosely grouped, they have the same ability to find useful structures in all kinds of data records~\cite{launer2014modern}. As branches of this experimental science~\cite{brandt1976statistical}, several well-established utilitarian tasks fall within the scope of data analysis: (\S~\ref{sec:data_management}) data management~\cite{van2020data}, which transform unorganized datasets with quality issues to high usable ones for data analysis, (\S~\ref{sec:explore}) exploratory data analysis~\cite{myatt2007making}, which helps analysts to interact with highly complex databases and tools which they are not familiar with, (\S~\ref{sec:da_methods}) implementation of data analysis methods~\cite{brandt1976statistical,nisbet2009handbook}, which imperatively implement data analysis tasks with primary operations, and (\S~\ref{sec:correctness}) assessing analytical results~\cite{bruce2020practical,kenett2016information}, which assesses the reliability and practicability of analytical conclusions. We organize their definitions, overview them within the scope of our topic, and related surveys about applications of LPMs in \S~\ref{sec:task_solving}.

Although LPMs can be introduced in alignment with these tasks, it is important to further identify the specific challenges that hinder the seamless execution of complex analytical tasks, which LPMs can help overcome more effectively. In this paper, we revisit these tasks with emphasis on introducing LPMs and then provide a comprehensive and concise summary of the key challenges and their subordinate sub-challenges. These challenges are related to the systematic optimization of data analysis through LPMs, each of which consists of several sub-challenges. The sections (\S) correspond to where LPMs can address these challenges and drive optimization.

\paragraph{Scalability of Data Analysis (\S~\ref{sec:dsl})}  
As data analysis rapidly advances, there are growing concerns about the limits of what it can handle. With the increasing volume and variety of data, traditional analysis methods can struggle to keep up, especially when dealing with data in different formats, sizes, and resolutions. Some of the main challenges include whether existing knowledge can be applied to more complex systems, and how to keep analytical methods up to date.
\underline{(1) Representation learning of concepts.} This involves creating links between real-world concepts and terms in an analysis problem, helping to clarify the meaning and semantics of terms within the problem's context. Representation learning maps structures in data to concepts and operators. Structural methods scale better for more complex systems, due to their high maintainability.
\underline{(2) Reasoning with domain-specific concepts.} At the same time, data analysis methods must be continuously expanded to keep up with the fast-changing demands of analysis. Universal algorithms that can extract concepts from data samples and generate new insights are crucial, as reasoning is the key driver for the evolution of analytical methods.
\underline{(3) Consolidation of domain-specific language.} Fragmented approaches can hinder consistency and reproducibility, making it hard to establish common benchmarks. Consolidating methods is essential to encourage collaboration, ensure the maintainability of high-quality solutions with thoroughness, and improve the reliability of results across different industries.

\paragraph{Accessibility of Complex Models (\S~\ref{sec:interpretability})}  
While the effectiveness and scope of data analysis continue to grow, the operability of complex models remains a significant challenge. Data analysis prefers more accessible methods to avoid specific risks and inject prior knowledge into these models. \underline{(1) Data analysis interface.} Improving interfaces is essential to ensure that human intervention and alignment are both efficient and effective. It further aligns the goal of data analysis with the provided data, methods, and models.
\underline{(2) Interpretable and editable methods and models.} Although advanced models can provide valuable insights, their "black-box" nature often hides the decision-making process. This lack of transparency makes it difficult to validate hypotheses, communicate results to non-technical stakeholders, and build trust in the findings.


\paragraph{Data Quality Issues (\S~\ref{sec:data_quality})}  
Data quality directly impacts the reliability of the conclusions drawn from data analysis. Data quality issues involve consistency, accuracy, completeness, timeliness, and identity of the same concept, which are essential for reliable analysis. They can be more concisely concluded with consistency and completeness, assuming that finally acquired data is up to date and concepts learned are all identifiable. \underline{(1) Robust against errors.} In this context, consistency refers to the absence of contradictions within the data, ensuring that integrated heterogeneous data sources adhere to compatible formats and standards. Achieving consistency requires extensive preprocessing and harmonization to create unified datasets or acquire a model that is robust to inconsistent datasets. \underline{(2) Representative data sampling/generating.} Completeness involves addressing missing values, gaps, and incomplete records that can arise during data collection and integration. Without robust management of consistency and completeness, analytical outcomes are compromised, potentially leading to misinformed decisions and reduced stakeholder trust.

\paragraph{Automated Machine Learning (AutoML) (\S~\ref{sec:auto_ml}
)} Traditionally, the above challenges have been tackled through manual efforts and ad-hoc solutions for various data analysis tasks. For application sectors where human interference is not always available, self-disciplined decision plans should be made with acquired data. In the context of machine learning, AutoML refers to the automated search for highly effective machine learning methods. Philosophically, machine learning involves inducing concepts from finite samples within a hypothesis space. Thus, we consider AutoML to be the most appropriate term for the automated search for data analysis methods and models.\underline{(1) Consolidation of AutoML.} The first challenge is to enhance the performance of AutoML within the existing constraints of the hypothesis class. Specifically, the primary concern within the AutoML community is improving both the efficiency and effectiveness of AutoML.\underline{(2) Scaling AutoML.} Additionally, extending and relaxing the effective scope of AutoML with structural guidance presents a challenge. It is more meaningful to introduce a more scalable and human-centered AutoML. For example, domain experts may input their knowledge into the scaled system to configure more suitable data analysis methods. This would make AutoML more meaningful for solving more technical and mathematical problems when data scientists have deeper needs.


\subsection{Introducing LPMs into Data Analysis} % 下一级子章节

While (Pre-trained Language Models) PLMs can only operate on a sequence of tokens or encoded latent embeddings, other foundation models can operate on various multi-modal data which also preserve algebraic or statistic structures, formalizable logic clauses, and algorithms. Foundation models and large pretrained models (LPMs) may refer to all the above models which benefit from pertaining large amounts of parameters with enormous datasets to perform all kinds of reasoning and decision tasks. Taxonomy for the LPMs according to their data modality, model architecture, and training methods are well organized in specialized surveys~\cite{YangJTHFJZYH24,zhou2023comprehensive,LiangWNJ0SPW24,videounderstanding,yin2023survey,wu2023multimodal}. 

In this paper, we dig deeper into why, and how LPMs can systematically strengthen the utility and scalability of data analysis. We conclude that several advantages of LPMs can benefit data analysis. 

\paragraph{Ability to name and understand symbolic and formal concepts.} LPMs provide opportunities for operating formal logical systems. Separated from other machine learning methods, the combination of operating with logical systems of different modalities, completeness, and consistency is the key advantage of LPMs. Their pretext tasks (e.g. next wold prediction on multiple corpus) can represent manipulations of a variety of data~\cite{yuan2023power}. LPMs pretrined by large amounts of text and code can understand and compose complex semantics and concepts defined by nested or recursively built syntax structures~\cite{phi1}. When processing a wide range of objects, LPMs can approximately correctly choose operations and morphisms to build complex concepts~\cite{009brown2020language}. 

For example, a neural symbolic system based on LPMs can help analysts construct a formalized representation of a problem, helping them to mitigate or ignore complexities of syntax and semantic checking~\cite{Bavishi2022NeurosymbolicRF}. Code generation systems, e.g., Copilot, provide different modes with high usability to help programmers implement analysis programs~\cite{Barke2022GroundedCH}. They can not only understand declarative high-level programming languages but are also designed to compose them correctly according to human instructions and intentions. 

\paragraph{Composing probably approximately correct (PAC) concepts during in-context learning.} LPMs can perform multiple tasks simply with brief demonstrations and a few samples without training and fine-tuning. Each of those inference steps or chains can be seen as an entire approximate correct identification of concepts. Primary knowledge or common sense, which is frequently presented in pertraining datasets, is induced by the structure of datasets and approximated by the data distribution. This primary knowledge is useful for compressing general-purpose concepts and hypotheses. 

In \S~\ref{sec:interpretability}, we introduce concepts class, learning algorithms, hypothesis class, and data distribution in the languages of probably approximately correct (PAC) learning theory, which can recover the most purposes of data analysis. This will help us to divide intrinsic methods and research directions that introduce the power of LPMs into several categories. We will see how the composition of multidomain operators and concepts helps to introduce multidimensional optimization into the sector of data analysis.

The purpose of composing concepts and hypotheses in a data analysis problem is to separate specific runtime implementation of methods with the goal of analysis, which is the core of systematic optimization of data analysis. In this process, LPMs are proven to be playing a significant part. 

\paragraph{Generalization across different modalities and categories.} Foundation models can generate and make judgments about unseen objects from the target category (e.g., images) using the structural information from the source category (e.g., texts)~\cite{Yuan23a}. This generalization ability can't be fully estimated by only discussing statistical generalization~\cite{ReizingerUMKBH24}. Operations and laws in algebras, which are demonstrations of structures of logic systems, perform exportation in reasoning. Correct operation on these structures made by LPMs should be identified with disentangled data distribution and algebraic knowledge. The key factor of this type of generalization is the ability to compose maps between these structures of different modalities and categories~\cite{DuK24}. 

Practically, intrinsic data constructors, operations of the data, algebraic structures, external knowledge, and codes for analysis planning can be composed and abstracted into new primitives and concepts. Conventional methods are strongly dependent on complex formal proofs and analysis from experts and mathematicians to gain well-defined abstractions. All of the libraries consist of complex domain-specific knowledge and methods with unknown and vague sematic definitions making it hard to achieve analytical purposes efficiently, not to mention optimizing their properties like generalizability, robustness, and execution efficiency. Therefore, precisely understanding and generating formally correct DSL programs according to their compositionalities and building a more human-needs-centered data analysis interface is fundamental for introducing more systematic optimizations into data analysis.


LPMs bring opportunities for systematic optimization of data analysis. Instead of introducing challenges with the order of life circle of LPMs, we are more concerned with completeness and thoroughness where LPMs help to achieve the purpose of data analysis. LPMs have shown multi-dimensional advantages in introducing systematic optimization into data analysis. Providing the capability of enhancing the automation of formal reasoning with DSL and integrating interdisciplinary knowledge, LPMs introduce various opportunities in the scope of data analysis. This paper is a systematic review of LPMs-empowered data analysis methodologies, our contributions are listed below.

\begin{itemize}
    \item We provide a comprehensive organization of utilitarian data analysis tasks and thoroughly analyze the value proposition of incorporating LPMs in (\S~\ref{sec:task_solving}). We further focus on technical and in-depth aspects, such as scalability, interpretability, and other key factors that enhance data analysis in (\S~\ref{sec:methods}).
    
    \item We not only broadly introduce applications of LPMs in data analysis in terms of key tasks and methodologies, but also dig into much deeper details of obstacles and theoretical analysis, making a sound evaluation of challenges for every application domain.
    
    \item We aim to extend data analysis with previous analytical results from LPMs, generalizing their application conditions and building a solid foundation for further innovations. We summarise state-of-the-art methodologies and findings, clarifying their (dis)advantages and providing a roadmap for challenges and further research.

\end{itemize}


% \begin{figure}[H] % 图片，替换example.png, H是精确位置
% 	\centering
% 	\includegraphics[width=1\textwidth]{overview.png}
% 	\caption{综述的整体结构}
% \end{figure}

\section{Data Analysis Key Tasks Solving Empowered by LPMs}\label{sec:task_solving}

We first review challenges met by conventional data analysis, new methodologies, and new opportunities, including data management, exploration and visualization of data, analytical methods and models, correctness and practicality, robustness, and incremental improvement. We put stress on the complementarities of conventional methods and new techniques, pointing out the key orientations for empowering data analysis to preserve the advantages of traditional theoretical results and smoothly introducing LPMs to boost performance and efficiency. This section formulate the applications and benefits of introducing the power of LPMs.

\subsection{Data Management}\label{sec:data_management}

In \textit{Data Management: A Gentle Introduction—Balancing Theory and Practice}~\cite{van2020data}, the authors expand and generalize the concept of data as an asset. They also present the definition of data management~\cite{international2017dama}.

\paragraph{Definition.} Data management is the development, execution, and supervision of plans, policies, programs, and practices that deliver, control, protect, and enhance the value of data and information assets throughout their lifecycle.

To fit in the skeleton of the topic of data analysis, we narrow down the topic of data management to include data collection, storage, cleaning, and transformation. Managing real-world data encounters complex problems composed of heterogeneity, systematic and random noise, irregularity, and contradictions. \cite{fernandez2023large} proposed several strengths and challenges in applying large language models to data management. We organize surveys for more utilitarian methods and interaction between the management of data and other components, optimizations of data analysis. 

For performing a data analysis task, the analyst should first ensure the declaration of analytical objects and operations are precise and non-ambiguous~\cite{Zhou2019ASO}. However real-world data always contains various types of errors and inconsistencies~\cite{022batini2009methodologies}. Data management aims to overcome these challenges to provide complete and consistent datasets given a well-defined analytical query. In the field of data manipulation, collection, and discovery, LPMs show powerful potential in merging multi-domain heterogeneity data and knowledge, consisting of domain-specific terminologies, libraries~\cite{Ellis2020DreamCoderGG}, facts~\cite{Tang2024WorldCoderAM}, distributions~\cite{sordoni2024joint}, and external knowledge. 

Well-managed data should share several of the same good properties. Furthermore, the performance of data analysis always highly depends on the accuracy, completeness, consistency, identity of the same entity, and timeliness of data. Completeness refers to the collection and storage of all necessary data. Missing entities and attributes may contribute to bias and errors~\cite{037little2019statistical}. Consistency refers to the fact that there should not be contradictions between data sources or data collected at different times. The identity of the same entity refers to entities that share the same description in multiple data sources~\cite{khoshafian1986object}. Timeliness refers to data not being outdated to reflect current circumstances, ensuring timeliness helps to fully make use of available data during its most valuable time which is important for making dynamic decisions~\cite{022batini2009methodologies}. 

One way to achieve the goal of data management on datasets with quality issues is data cleaning. To enhance data quality by filling in missing values, correcting errors, and decreasing duplications and inconsistencies, IterClean~\cite{ni2024iterclean} propose an LPMs-based method for iteratively data issue detection and reparation that achieves state-of-the-art performance. LPM-based data wrangling solves multiple tasks such as data cleaning, transformation, and integration and serves as an important data management method. \cite{vos2022towards} propose a low-resource fine-tuning method for task-specific or data-specific data wrangling methods, aiming to reduce high expertise, manual efforts, and storage costs for finetuning. DEEM~\cite{deem} uses LPMs to understand declarative wrangling demands, routing to data of interest and operating with them using generated codes. \cite{qi2024cleanagent} propose an agent for data cleaning, CleanAgent. It can compose DSL for error-type-specific data cleaning to achieve automation for data repair.

LPMs can discover statistical and deduce logical relations~\cite{Wang2023SoloDD}. \cite{Nobari2023DTTAE} proposes DTT, an LPM-based method for finding linkage implied in multi-table datasets, which can be used in data integration with simply few-shot prompting. \cite{zuo2022spine} proposes another method for finding linkage, and though it is not an LPM-based method, it proves that this task can be done in the program by-example (PBE) style. \cite{Li2024IsPB} shows that LPMs can do PBE by in-context learning. It can be used for tasks such as regular expression construction, string transformation, symbol regression, and formal proof, which points to a new direction in the field of data integration. 

Feature engineering is another important task for improving the usability of data, specific form and representation of data can greatly affect efficiency of downstream analysis, which is discussed in detail in \S~\ref{sec:auto_ml}. LPMs also helps to build data processing piplines which performs feature engineering. For example, \cite{Hollmann2023LargeLM} proposes a context aware method that builds automated feature engineering piplines—CAAFE—which can automatedly keep changes according to performance improvement.

These methods show the progress of benefitting data management from LPMs. Meanwhile, this research area is super young and full of opportunities for more advanced tools based on LPMs. Some of the methods take advantage of the ability of LPMs to operate on DSL to manipulate data to achieve data management goals. We will go into detail with methodologies for enhancing understanding and manipulating DSL in \S~\ref{sec:dsl}. 

\subsection{Exploratory Data Analysis}\label{sec:explore}

Exploratory data analysis (EDA) and data visualization are essential to intuitively understanding the features and patterns of datasets. Exploratory data analysis aims to help analysts retrieve and aggregate patterns of interest interactively, finding suitable abstractions and partitions that are not only stable but also understandable. Several issues and steps are proposed in \textit{Making sense of data—a practical guide to exploratory data analysis and data mining}~\cite{001barton2012making} to be considered to be taken and interactive with each other in any exploratory data analysis—problem definition, data preparation, implementation, deployment. We consider these steps to be operated in other tasks. This section focuses on the interaction between analysts and platforms to perform these tasks toward an analytical need. 


Exploratory data analysis can help analysts to better dig into unknown structures (e.g., analytical, geometric, and algebraic properties) implied in complex datasets. For example, modern databases provide multiple analytical interfaces for analysts to help them flexibly query instances. According to the values, by using statistical, machine learning, and graphic methods, EDA helps to identify main features, anomalies, and implicit relations in data. Implementing methods composed of methods routing to valuable parts of data and exhibition methods is filling the gap between general-purpose libraries and ad-hoc exploration solutions which can present a huge cost of manual labor. Declarative methods help to mitigate this obstacle, but real-world data would be so complicated for higher-level abstractions~\cite{heer2010declarative, shih2018declarative, kim2022cicero}. 

There are LPM-based methods that enhance interfaces for EDA, and some of the other methods fill the gap between general-purpose methods and task-specific demands, they all made significant successes. \cite{zheng2024revolutionizing} introduces DQA, a benchmark for evaluating the question-answering performance of LPMs based on databases, which provides a more abstract declarative interface for EDA. Analysts can declare one-off EDA tasks, and then LPMs can infer instances dependent on libraries that can solve sub-tasks and composite the implementation of the task. For parsing and routing to valuable parts of datasets, not only can the analysis of tabular datasets benefit from LPMs, but unstructured and semi-structured data can also be more easily explored with the help of LPMs.

For example, \cite{ko2024filling} proposes an LPMs-based method for parsing semi-structured data like HTML data into knowledge that is easy to explore and more readable documents. In terms of data visualization, \cite{ma2023insightpilot} proposes InsightPlot. It can construct different types of insights such as objects, types, and attributions, and allows analysts to gain more insight into complex structures with iterative interaction with LPMs. Combining the ability to do interactive parsing, data routing, and visualization, the introduction of LPMs provides an easy-to-use interface for exploring scalable databases. Introducing the power of 

LPMs can also help analysts to better and faster understand data or task-specific operations and data processing pipelines, to explore more complex analytical tools and insights with more complex logical structures. \cite{Dibia2023LIDAAT} proposes LIDA, pointing out that LPMs not only can generate charts by manipulating graphical languages but also provide explanations to novices about the content of images and their insights, offering a human-centered data visualization interface. \cite{nam2024using} introduces a large-model-based code explanation tool GILT, which helps users quickly understand and implement large sections of data analysis code. \cite{GrandWBOLTA24} proposes LILO, which generates doc-strings for obscure imperative codes. This can enhance the feasibility of non-computer experts in understanding and exploring code repositories.

LPMs can also help to predict user intentions. This could help to resolve vague and ambiguous analytical intent. \cite{dubiel2024device} propose a query intent prediction method, which can improve the efficiency in contrast with the dump query method without perception of analytical needs. \cite{li2024can} also discussed the feasibility of using large language models as database interfaces. Similar to which involves encoding human intentions represented by natural language into query statements. These methods perform abductive reasoning to provide the most useful query advice according to the present goals of data analysis.

Exploratory data analysis is needed in various industries, covering both structured and semi-structured data. LPMs can parse semi-structured data through direct or encoded methods, while structured data is more suited for exploration and analysis through rule-based approaches. In \S~\ref{sec:interface}, we put stress on the potential for systematically enhancing interfaces for data analysis which can promote the development of EDA. In \S~\ref{sec:explanable}, we generalize the boundary of exploration for not only the dataset but also concepts that can be learned from data and delve into explainability and editability, demonstrating how LPMs enhance rule-based or principle-based machine learning and its advantages.

\subsection{Implementing Data Analysis Methods and Models}\label{sec:da_methods}

In contrast to EDA where analytical objects are always unknown or vague at first and need to be unambiguously fixed, data analysis methods include widely used statistical methods and machine learning methods that are probably approximately correct (PAC), composed of needed knowledge and mathematical structures. Complicated veins make it hard to systematically and universally represent and fully use these methods. Choosing a suitable one depends on the problem properties and the data characteristics. For example, linear regression is designed for predicting continuous data, while decision trees are designed for classification~\cite{032hastie2009elements}. This selection of models can be seen as choosing different hypothesis classes for approximately identifying concepts of interest, which is detailed in \S~\ref{sec:explanable}. 

Choosing methods and models for well-defined tasks is an optimization over a disjoint union of multiple model classes and their parameters. The second concern with the models is the explainability and editability, which would be essential for high responsibility and efficiency. External logical knowledge which would be hard to disclose from data distribution is also hard to obtain without domain expertise~\cite{031guyon2003introduction}. Besides, learned parameters and rules can be difficult to understand, meanwhile, it's hard to effectively and efficiently inject external knowledge for better performance or bias reduction, and transfer learned concepts for further analysis. The lack of interpretability presents practical and ethical challenges to data analysis. 


To solve these challenges, LPMs introduce formal reasoning-based methods, which show some advances in understanding analysis methods and data to be analyzed. LPMs can help to search hyperparameters to guide machine learning with higher performance~\cite{sayed2024gizaml}. Furthermore, LPMs can also perform as statisticians who perform in-context algorithm selection with provable performance~\cite{bai2024transformers} by mimicking gradient descent during inference. \cite{HuZWCM0WSXZCY0K24} proposes a benchmark—InfiAgent-DAAgent and an agent for data analysis—DAAgent which involves multiple analytical tasks such as outlier detection, distribution analysis, and machine learning, etc. \cite{EoTGE} propose guided evolution (GE), which modifies codes for PyTorch models using LPM directly to evolve the models. 

Consolidating the inference of LPMs into simpler methods and models helps to gain interpretability. \cite{singh2023augmenting} proposes Aug-Linear and Aug-Tree which makes predictions based on N-grams in text. Predicted responses of voxel (specific points of the human brain where the strength of activity is to be measured) have exceeded BERT performance with simple linear models. \cite{nam2024optimized} proposes OCTree, which augments tabular data for improving downstream performance. 

Domain-specific data analysis methods often have stringent requirements for the objects of analysis \cite{020arlot2010survey}, while general analysis methods lack the formalization and discussion of external knowledge. Effective analysis requires transcending statistical generalization methods, which performs PAC learning on finite samples on an unknown distribution~\cite{angluin1988queries}, and gains the support of mathematical logic's necessity. \cite{HsuMTW23} proposed LEFT, which consolidate concepts in some domain (2D movement) to general concept across domains (3D movement). \cite{SongY00024} proposed a tree-based variational inference method to encode event sequences into strict logic expressions. \cite{WangCY0L0J24} proposes CodeAct, which substitutes LPM actions into executable codes, producing a more rigorous decision implementation. \cite{GrandWBOLTA24} introduces LILO, which produces docstrings for complex implementations that can improve interpretability and help LPMs reasoning by inducing knowledge directly with observations from these docstrings. These docstrings are representations of implementations for a group of thoroughly solved problems~\cite{yuan2023power}. Their composed structures represent possible analysis solutions~\cite{zhengprise}.

More generally, code generation makes it possible to deduce principles from value orientations of data analysis directly and consolidate them with unambiguous formal language~\cite{KoziolekGHALE24}. The robustness and stability of traditional data analysis models are key to ensuring their reliable application in different environments. From a more systematic view, LPMs can consolidate knowledge more imperatively through code repositories. LPMs gain more and more attention in understanding and repositories. \cite{jain2024r2e} proposes R2E which turns repositories into LPMs agent environments. \cite{repocomp} proposes Repoformer, which can solve code completion in the user's repository. 


\subsection{Assessing Analytical Results} \label{sec:correctness}

Correctness and applicability are the most important criteria for data analysis, reflecting the practicality of data analysis. In this section, we refer to correctness as implementations, statements, proofs, and derived theories correct computationally and logically, according to axioms and principles. The domain relevance of the results determines whether they can effectively guide decisions and actions \cite{027davenport2017competing}. Applicability emphasizes whether the results can be translated into concrete action plans \cite{040shmueli2011predictive}. The causal effect assesses the effectiveness of the results in real-world applications, such as improving sales or optimizing processes \cite{038provost2013data}. 

In real-world problems, bridging the gap between data analysis and practical applications still requires substantial labor and complex manual methods. Moreover, implementing data analysis programs using general-purpose programming languages still faces enormous demands for input validity, termination, verification, and proof. Solving real-world problems often involves complex nested and recursive logic, and finding analysis methods that are globally, locally, and necessarily correct \cite{shao2023synthetic} is the main challenge in handling these tasks \cite{yao2024tree}. 


Mathematical proofs provide assessments of thoroughness for a group of solving problems, which can always be seen in software tests~\cite{schumann2013automated}. LPMs-based code generation and theorem-proving systems \cite{Pei2023CanLL,Wang2024TheoremLlamaTG} make it possible to develop and assess new self-organizing data analysis methods. LPMs can efficiently generate Turing-complete formal languages and code \cite{Li2024IsPB}, where data analysis tasks can be thoroughly done with concise implementation. They adopt more rigorous and complete cleaning and analysis methods, helping users address a wide range of data quality issues and build a bridge between data analysis problems and specific implementations to achieve precise and unambiguous data cleaning \cite{qi2024cleanagent} and analysis results. 

LPMs-based data analysis and auxiliary systems have the potential to change the game in data analysis by improving the effectiveness and efficiency of real-world data analysis problems that involve large data volumes, complex data quality issues, and intricate structures \cite{fernandez2023large}. Data analysis is a process of continuous improvement and iteration. By establishing feedback mechanisms, optimization directions can be constantly gathered from practical applications, allowing for model optimization and adjustment. Iterative optimization emphasizes continuous improvement in aspects such as model performance, data quality, and analysis methods to adapt to changing environments and needs \cite{033kaelbling1996reinforcement}.


This places greater demands on quickly obtaining feedback from the environment. The cross-domain integration driven by LPMs not only enhances the comprehensiveness and depth of data analysis but also facilitates communication and collaboration among professionals from different backgrounds by providing interpretable analysis results. For example, LPMs can be used to integrate data from different fields to form a comprehensive analysis framework, thereby offering more comprehensive and accurate insights~\cite{yang2024give, hu2023survey}.


\section{LPMs Empowered Systematic Optimization Methodologies}~\label{sec:methods}

In this chapter, we will explore how large models systematically optimize data analysis. From domain-specific language understanding, accessibility of complex models, and data quality optimization, to automated machine learning, PLMs have demonstrated significant potential at every stage. Nevertheless, we also point out the current challenges and emphasize the importance of future research in algorithms, data quality, and system efficiency. Through these studies, we hope to drive data analysis systems toward becoming more efficient and robust.

\subsection{Domain-Specific Language Understanding}\label{sec:dsl}

"The basis of all human culture is language, and mathematics is a special kind of linguistic activity." Arnold \& Manin (2000)

Domain-specific language (DSL) refers to languages specifically designed for a specific application domain. It reflects specialization and abstraction of human understanding, improving problem-solving and communication. For every data analysis expert in any domain, understanding DSL is a fundamental task, which plays an important role in every stage of data analysis. Till now, in domains like supply chain, legal, and financial field, it costs multiple years of training and experience accumulation for the experts to understand the objects and operations in a domain-specific language fully~\cite{garcia2010using}. 


\subsubsection{Representation learning of concepts.} Representation learning plays a pivotal role in the field of machine learning. It aims to discover and extract effective features and representations. Representation learning in a narrow sense refers to techniques like manifold learning which preserves the geometric shape of the original distribution in support of classification, regression, clustering, and data generation.~\cite{buchholzrobustness, feyposition} In a general sense, representation learning can be related to representation theories in the language of mathematics, which preserves morphisms and structures of categories, preserving symmetry and equivariance, providing algebraic tools, and enhancing optimization and presentation abilities~\cite{yuan2023power, blaauwbroekgraph2tac, HansenCF24}. 

Representation learning provides us with tools to compress data and implement algorithms in a concise form, which can be seen as a new DSL. In terms of data compression, \cite{DeletangRDCGMGW24} has proven that language models can be seen as general compression algorithms, it shows that language models can perform lossless compression on images, audio, and videos, which can be far more efficient than conventional algorithms. \cite{GrandWBOLTA24} propose a code compressing and documenting method, LILO, based on LPMs, which can consolidate code into more reusable and readable forms. \cite{zhengprise} propose PRISE which is a compression algorithm for temporal actions made by agents, abstracting valid components into skills that can be seen as representing algorithms discovered from data. Using this, analysts can perform efficient and precise retrieval of both data and composable operations on them, \cite{KoziolekGHALE24} propose a retrieval argumentative method for control code of automated systems which bound to representations that supply to domain-specific standards. 

The introduction of representable rules and principles makes it easy to leverage what is discovered from one set of data to analyze others~\cite{yuan2023power}. Analysts can easily transduce this explicit knowledge on demand. Causes and their effects can be found in the dataset leveraging causal or interventional representation learning in an interpretable and grounded way~\cite{ahuja2023interventional}. They negate existing goals of the analysis to create new goals that are more feasible. To systematically boost the ability of data analysis on more complex systems like code repositories~\cite{jain2024r2e}, disciplinary knowledge of specific domains, and their application fields, we need more foundational representation theories~\cite{yuan2023power} that LPMs can first bring in. 


\subsubsection{Reasoning with domain-specific concepts}

Representation learning for DSL contributes significantly to the efficiency and quality of analysis and decision-making, emphasizing both inductive and deductive logic. Reasoning involves composing these representations toward a predefined goal, which not only induces evidence from datasets and adjusts the posterior but also deduces applicable rules to reach necessarily correct conclusions. This section summarizes how LPMs apply to principles and conditions of induction and deduction in reasoning, making systematic enhancements in the field of data analysis.

\paragraph{Principles of Induction.} Inductive reasoning involves deriving general principles from specific observations or instances of collected data. In finite or infinite deterministic systems, such as mathematical sequences or physical laws, the inductive method can identify deterministic principles and rules with certainty. However, in stochastic systems—such as datasets with various quality problems to optimize, as discussed in \S~\ref{sec:data_quality}—we can only pursue hypotheses that are approximately correct. These hypotheses are subject to validation and may need to be revised as more data becomes available, which will be detailed in \S~\ref{sec:explanable}.

In real-world applications, successful inductive reasoning relies on several key principles:

\underline{Completeness of Representative Sampling.} Ensuring that the data collected accurately and sufficiently reflects the population or phenomenon being studied. This reduces sampling bias and enhances the generalizability of the inductive conclusions~\cite{037little2019statistical}.
    
\underline{Consistency and Robustness Against Errors.} High-quality data and resilience to errors are essential for reliable inductive reasoning. LPMs contribute by automating data cleaning and preprocessing tasks, such as handling missing values, correcting errors, and removing inconsistencies~\cite{ni2024iterclean, qi2024cleanagent}. This improves the accuracy of the induced rules and principles.
    
\underline{Compatible Logical Structures and Sufficient Prior Knowledge.} Building comprehensive models that account for all relevant variables and interactions. LPMs assist in identifying hidden patterns and relationships that might be overlooked using traditional methods~\cite{ma2023insightpilot, Dibia2023LIDAAT}. These logical structures can be leveraged to integrate existing domain knowledge to inform the inductive reasoning process. LPMs can merge multi-domain heterogeneous data and knowledge bases, enhancing the richness of the inductive models~\cite{Ellis2020DreamCoderGG, Tang2024WorldCoderAM}. This leads to more guided and consistent induction steps.
    
\underline{Well-Defined Goals.} Having clear objectives for the inductive analysis ensures that the reasoning process is focused and relevant. LPMs can interpret natural language descriptions of goals and translate them into actionable analytical tasks~\cite{li2023resdsql, gu2023few}. Ensuring that hypotheses are falsifiable is essential for scientific rigor.

By adhering to these principles, inductive reasoning becomes more robust and reliable. LPMs enhance this process by providing advanced tools for data management, pattern recognition, and knowledge integration. They effectively handle complexities such as heterogeneity, noise, and inconsistencies in real-world data~\cite{vos2022towards, deem}, thereby improving the completeness and consistency essential for sound inductive reasoning. This empowers analysts to derive meaningful insights and develop approximately correct hypotheses, even in the face of data imperfections and uncertainties.


\paragraph{Principles of Deduction.} Deductive reasoning converts principles and axioms into rules that reason about specific instances. The importance of deduction in data analysis cannot be overstated, as deductive reasoning provides the foundation for deriving necessarily correct conclusions from established principles. When applying deductive reasoning, it is necessary and sufficient to consider several fundamental principles. Reasoning based on deduction can be feasible and correct when these principles are fulfilled. Local properties of successful deduction include soundness, which ensures the preconditions are correct, and formal validity, which ensures the rules used are concise and unambiguous. Global properties include consistency, completeness, and ensuring that no contradictions exist in propositions, as well as all true statements can be proven using axioms and rules.

\underline{Fulfilling Local Properties.} LPMs enhance deductive reasoning by assisting in formal reasoning-based methods, which are crucial for understanding analysis methods and the data to be analyzed and locally depend on formal validity and soundness of preconditions. For example, LPMs can generate formal proofs and Turing-complete formal languages and code~\cite{Li2024IsPB} which have high formal validity, improving the efficiency of problem-solving by constructing solutions that conform to nested and recursive logic~\cite{Khakhar2023PACPS}. This allows for more rigorous and complete analysis methods, helping users address a wide range of data quality issues and build bridges between data analysis problems and specific implementations to achieve precise and unambiguous results~\cite{qi2024cleanagent}. Moreover,~\cite {Li2024IsPB} have shown that LPMs can treat each inference as inductive and possibly correct in-context learning process, which also shows the ability for the discovery of concepts that would enhance soundness in real-world applications.

However, challenges arise due to inherent limitations in logical systems, as highlighted by Gödel's incompleteness theorems, which state that any sufficiently expressive formal system cannot be both complete and consistent. This implies that when we enforce strict consistency in our logical frameworks, we may sacrifice completeness—the ability to derive all true statements. In the context of data analysis, imposing such strong constraints of absolute consistency might limit the system's capacity to reason about complex or contradictory data, potentially diminishing the depth and scope of analysis.

\underline{Compromising of Consistency.} To address this issue, some analysts introduce paraconsistent logic, a non-classical logic that tolerates contradictions without leading to triviality—where any statement becomes provable. This approach allows reasoning processes to continue effectively even in the presence of inconsistencies, which are common in real-world datasets due to noise, errors, and conflicting information~\cite{022batini2009methodologies}. By incorporating paraconsistent logic, LPMs can handle contradictory data more robustly, enhancing the reliability of analytical outcomes~\cite{037little2019statistical}.

\underline{Compromising of Completeness.} Practitioners must therefore balance between expressiveness—the ability of the logical system to represent complex concepts—and decidability—the feasibility of algorithmically determining the truth value of statements within the system. An overly expressive system may become undecidable, making it computationally impractical for analysis. LPMs contribute to achieving this balance by leveraging advanced reasoning capabilities that handle complex, expressive representations while maintaining computational efficiency~\cite{Pei2023CanLL, Wang2024TheoremLlamaTG}. This balance is crucial in designing logical systems for data analysis that are both powerful and practical, enabling more flexible and comprehensive analysis of complex datasets.

Moreover, the robustness and stability of analytical models are essential for their reliable application in different environments~\cite{029dietterich1995overfitting}. LPMs contribute to enhancing the robustness and generalization ability of models by incorporating external logical knowledge, which is often hard to disclose from data distribution and challenging to obtain without domain expertise~\cite{031guyon2003introduction}. By leveraging mathematical derivations and formal proofs~\cite{wang2023large}, LPMs help analytical approaches achieve greater robustness and generalization performance, thereby strengthening deductive reasoning in data analysis.

\subsubsection{Consolidation of DSL}

In support of reasoning, LPMs can perform as components of a family of logical systems, in which we can balance between incompatible principles of complex systems, such as consistency and completeness. Representation learning and reasoning can enhance each other toward the goal of analysis. In terms of consolidation of DSLs, LPMs can be used as automated administrators of repositories and knowledge bases. Data analysts should always decide which principles and implementations of frequently used operations or sequences of decisions are important and should be preserved. These can be compositions of top-down deductive reasoning of principles and goals and bottom-up inductive reasoning of examples and applications with formal or latent representations. There remain three challenges for consolidating DSLs efficiently and effectively.

\paragraph{Thoroughness.} To ensure thoroughness in consolidating DSLs, it is imperative to capture the full scope of domain-specific knowledge and operations without overlooking critical details. This involves a meticulous examination of existing principles, methodologies, and exceptions within the domain. LPMs can assist by systematically analyzing large datasets to identify patterns and gaps in knowledge bases, thereby highlighting areas that require further attention. Additionally, LPMs can help in managing data quality issues by automating data cleaning and transformation processes~\cite{ni2024iterclean, qi2024cleanagent}, ensuring that the consolidated DSL reflects accurate and comprehensive knowledge. However, achieving thoroughness demands a balance between comprehensiveness and practicality to prevent information overload and maintain system efficiency.

\paragraph{Reusability.} Reusability is a cornerstone for efficient DSL consolidation, enabling components and frameworks to be applied across multiple contexts and applications. By promoting modular design and standardization, LPMs can facilitate the creation of interoperable and adaptable code segments. This not only accelerates development cycles but also enhances consistency and reduces redundancy. For instance, LPMs can aid in generating reusable code repositories~\cite{jain2024r2e, repocomp}, and in creating generalizable data analysis methods that can be adapted to different datasets and tasks. The challenge lies in abstracting domain-specific elements sufficiently to allow for reuse without sacrificing the unique requirements of individual applications.

\paragraph{Understandable.} Making consolidated DSLs understandable is crucial for user adoption and effective implementation. This involves presenting complex logical structures and reasoning processes in a clear and accessible manner. LPMs can contribute by generating human-readable documentation and offering explanations of underlying algorithms and decisions. Additionally, incorporating intuitive interfaces and visualization tools can aid users in comprehending and interacting with the DSL. For example, LPMs can assist in exploratory data analysis by generating insights and visualizations~\cite{ma2023insightpilot, Dibia2023LIDAAT}, helping users to better understand complex data structures. The primary challenge is to simplify complexity without oversimplifying, ensuring that essential details remain transparent and accessible to users with varying levels of expertise.


\subsection{Accessible of Complex Models}\label{sec:interpretability}

Building upon the foundations of domain-specific languages (DSLs) and the consolidation challenges discussed previously, in this section we discuss the transformative capabilities offered by LPMs for data analysis interfaces. By integrating advanced representation learning and reasoning, LPMs enhance the way analysts interact with data and analytical tools. 

Then, we introduce the concept of probably approximately correct (PAC) from machine learning theory. Philosophically, the PAC theory encapsulates the ontological inquiry into real entities by quantifying the capacity of learning algorithms to approximate true concepts from finite samples. Simultaneously, it emphasizes the process of distilling essence from phenomena, thereby reflecting the significance of essentialism and conceptualism in comprehending and defining learning tasks. The transparency and understandability of the learning procedure and automatedly learned concepts contribute to interpretable and editable machine learning.

\subsubsection{LPMs Enhanced Data Analysis Interface}\label{sec:interface}

Enhancing the data analysis interface not only improves data analysis efficiency but also helps users gain deeper insights into data. This includes interfaces for data manipulation, data visualization, data integration, data preprocessing and cleaning, machine learning and modeling, data exploration, real-time analysis and monitoring, and collaboration and sharing. LPMs provide an operational interface that offers significant benefits for human interaction~\cite{dubiel2024device}, serving as a bridge between human preference choices and real-world application problems.

This section explores how LPMs improve data analysis interfaces through intelligent routing to relevant data and methods, automated documentation and translation, and enhanced interaction emphasizing interpretability and operability.

\paragraph{Routing to Data of Concern}

Accessing the right data efficiently is a critical step in any analytical process. LPMs can significantly streamline this step by intelligently routing analysts to the data of concern. Leveraging their strong semantic understanding capabilities, LPMs interpret user queries to identify and retrieve relevant datasets from extensive repositories, even when dealing with different structured and semi-structured data types that often have different data manipulation interfaces.

For example, an analyst may inquire, "Find me the latest sales data for the Northeast region excluding returns." The LPM can parse this request, understand the specific requirements, and locate the precise dataset that matches these criteria. This capability reduces the time spent on manual searches and minimizes the risk of overlooking pertinent data, thereby enhancing the thoroughness of the analysis as discussed in the consolidation of DSLs.

LPMs also assist users in interacting with data analysis systems by establishing a mapping between business logic and data manipulation and exploration methods. Different data types require different interfaces; for instance, relational databases use Structured Query Language (SQL) and its dialects like PL/SQL. LPMs excel in generating data queries~\cite{li2023resdsql, gu2023few, cheng2022binding}, allowing users to formulate complex SQL queries through natural language instructions. This not only makes data retrieval more accessible but also reduces the likelihood of errors in query formulation.

For semi-structured and unstructured data, languages such as Cypher and Gremlin are used for querying graph databases. LPMs can aid in formulating these queries as well, enhancing the performance of systems that rely on knowledge graphs~\cite{huang2023kosa}. Additionally, specialized query languages like SPARQL and XQuery are used to interact with knowledge bases and XML data. By utilizing LPMs, analysts can interact with these systems using more user-friendly natural language commands~\cite{li2024flexkbqa, Lehmann2023LanguageMA}.

\paragraph{Routing to Methods of Concern}

Selecting appropriate analytical methods is as important as accessing the right data. LPMs assist in this aspect by recommending methods that align with the specific problem context and data characteristics. By understanding the DSL and the underlying principles of various analytical techniques, LPMs guide analysts toward the most suitable tools and methodologies.

For example, when working with statistical analysis, LPMs can suggest utilizing data frameworks such as Pandas and NumPy~\cite{lai2023ds}, interpreting natural language commands to perform data manipulation. If the task involves full-text search, log analysis, or real-time monitoring, LPMs can recommend the combination of search and analysis engines like Elasticsearch, significantly benefiting information retrieval~\cite{zhu2024retrieval}.

Furthermore, LPMs can serve as an interface between different dialects of systems. They can convert code or queries from one language to another, facilitating interoperability. An example is Mallet~\cite{ngom2024mallet}, a method that acts as a code converter, capable of converting queries or code snippets between different languages, thus aiding analysts who work across multiple systems.

\paragraph{Documenting and Translation}

Documentation is essential for knowledge sharing and maintaining the understandability of analytical processes. LPMs can automate documentation by generating detailed explanations of the steps taken during analysis, the reasoning behind method selection, and interpretations of results. They can also optimize existing interaction processes, participating in the optimization of program compilation and data manipulation processes~\cite{cummins2023large, cummins2024meta, li2024can}, thereby achieving significant computational performance improvements. Auto-documentation system helps to generate human-readable functions and variable names and docstrings which capture global structures of the repository, improving interpretability and improving downstream LPMs-guided search~\cite{GrandWBOLTA24}.

Moreover, LPMs can help analysts correct errors in interface languages. Due to the universal tendency of people to make biased choices, the interface language programs written by people often contain subtle errors. Researchers have used LPMs to correct errors in the interface language written by people, achieving significant results. For example, LPMs can help data analysts modify Excel formulas, quickly identifying the causes of formula failures and undiscovered errors~\cite{Bavishi2022NeurosymbolicRF}.

Additionally, LPMs can translate complex technical jargon into accessible language for non-expert stakeholders. They can also facilitate cross-lingual translation, making the findings available to a global audience. This capability ensures that the insights derived are understandable, addressing one of the key challenges in DSL consolidation.

\paragraph{Interaction}

Enhanced interaction between analysts and analytical tools is crucial for effective data analysis. LPMs contribute to this by providing interfaces that are both interpretable and operable. They offer explanations for their recommendations and decisions, making the analytical process transparent.

LPMs enable analysts to interact with data and models using natural language commands. This lowers the barrier to advanced analytical techniques, allowing analysts to modify parameters, run simulations, and visualize data without deep technical expertise. For instance, in the field of statistics and analysis, LPMs can interpret natural language commands to perform data manipulation using frameworks like Pandas and NumPy~\cite{lai2023ds}. This interactive capability supports the balance between expressiveness and decidability in reasoning processes, as previously discussed.

Researchers also utilize LPMs to optimize existing interaction processes. By determining conservative conditions through formal proof and verification, and by providing continuous system analysis and optimization suggestions, LPMs help analysts gradually approach optimal operations. Participation in the optimization of program compilation leads to significant computational performance improvements~\cite{cummins2023large, cummins2024meta}, and this finding applies to the optimization of data manipulation processes~\cite{li2024can}.

By integrating these enhancements, LPMs transform the data analysis interface into a more intuitive, efficient, and effective environment. They address the challenges of thoroughness, reusability, and understandability in DSL consolidation, ultimately empowering analysts to derive deeper insights and make informed decisions.



\subsubsection{Interpretable and Editable Method and Models}\label{sec:explanable}

Machine learning is an effective tool for data analysis, and its definition can encompass the objectives of data analysis, including the systematic optimization of machine learning methods. The following will explore the systematic optimizations that LPMs can bring to the field of machine learning, including optimizations in data quality, machine learning, interpretable machine learning, and the enhancement of large models for automated machine learning. Therefore, we will start from the theory of probabilistic approximation, dividing current work and directions into the manipulation of concept classes, hypothesis spaces, data distributions, and learning algorithms.

\paragraph{Definition.} In the most basic probabilistic approximation theory in machine learning theory, the most fundamental concept is PAC learning. Given a concept class $\mathcal{C}$, a distribution $\mathcal{D}$, and a hypothesis space $\mathcal{H}$. For $\forall c \in \mathcal{C}$, if there exists a learning algorithm $\mathcal{L}$, whose output hypothesis $h \in \mathcal{H}$ satisfies for $0<\epsilon$, $\delta < 1$ 

\begin{equation} P(\mathbb{E}_{x\sim \mathcal{D}}[\text{distance}(h(x), c(x))] \leq \epsilon) \geq 1-\delta \end{equation}

where distance measures the difference between the hypothesis and the concept.

\paragraph{Insight.} This definition discusses the goal of machine learning, which is to learn approximately correct concept classes from data distributions. A good analysis method also requires good concept classes, data distributions, hypothesis spaces, and learning algorithms. Ideally, the hypothesis space $\mathcal{H}$ exactly covers the concept $c$ that needs to be learned. However, this is often not achievable.


LPMs have the potential to address these challenges by utilizing human-understandable concept classes to construct hypothesis spaces that better meet analytical needs, thereby enhancing the interpretability and editability of machine-learning models. As discussed in \S~\ref{sec:data_quality}, LPMs can improve data quality by representative sampling, generating and helping to build methods that are robust to certain error types, and in \S~\ref{sec:auto_ml}, we see that LPMs serve as learning algorithms explicitly organize discovered and prompted knowledge from analysts, helping them automatically construct machine learning pipelines.

Explainable Artificial Intelligence (XAI) acts as a bridge between deep neural networks and human reasoning. Constructing explainable AI models is motivated by the need for realism and ethics in data analysis. Black-box neural networks often fail to provide combinable forms of knowledge, embedding both the logical and covariant components of problems into implicit state spaces. This opacity leads to undesirable consequences: data analysts and engineers cannot trace the causes of errors, resulting in issues of fairness and compliance, and ultimately leading to a loss of trust from users and decision-makers. Furthermore, these models make it difficult for engineers and data scientists to identify model deficiencies and edit decision-making or predictive behaviors.

As a result, data analysts across various industries prefer interpretable and editable machine learning methods. The question then arises: how can LPMs aid in the development of interpretable and editable machine learning? The key lies in their potential to overcome current obstacles in explainable machine learning by leveraging their capacity to explore logical systems with greater expressiveness and human-understandable rules~\cite{reizingerposition}. By doing so, LPMs can facilitate the construction of models that are both interpretable and editable, aligning with the practical needs of data analysis. Despite the promising advantages, integrating LPMs to enhance interpretability and editability in machine learning introduces several challenges that must be addressed.

\paragraph{Enhancing interpretability with high expressiveness.}

There exists a fundamental trade-off between the expressiveness of a model and its interpretability. Highly expressive models, such as deep neural networks, can capture complex patterns within data but are often opaque, making them difficult for humans to understand. Conversely, interpretable models, like decision trees and rule-based systems, offer transparency but may lack the expressiveness required to model intricate data relationships.

LPMs are adept at exploring logical systems with increased expressiveness while incorporating human-understandable rules~\cite{reizingerposition}. By leveraging LPMs, we can construct hypothesis spaces that balance expressiveness and interpretability, overcoming the traditional compromise between model complexity and understandability. One way to enhance interpretability without sacrificing expressiveness is to leverage LPMs to understand and interpret complex models for interpretable needs. \cite{nam2024using} propose an IDE plugin that can interpret complex code repositories whose code comments and documentation are scarce or hard to navigate. More pragmatically, analysts can distill LPM knowledge to simple and interpretable models~\cite{singh2023augmenting}. With constrained but enough expressiveness of simple models, analysts can make appropriate choices for consolidating augmented knowledge into simpler models.

LPMs also help in interpreting models, and complex data structures, e.g., \cite{ko2024filling} designed an LLM-based method to convert scientific data into the desired form. Though a database with complete records is highly expressive in capturing reality with fixed, it is hard to interact with and explore. \cite{zheng2024revolutionizing} proposes a question-answering method for databases. This involves creating interfaces that transform data types challenging for humans to comprehend (e.g., continuous numerical values, extensive codebases) into more accessible forms (e.g., Boolean variables, symbolic expressions, natural language descriptions, visualizations). Utilizing LPMs to generate human-like explanations can achieve a level of diversity and clarity that approximates or even surpasses human capabilities. It requires careful consideration of the necessary and sufficient conditions for effective reasoning. It is crucial to ensure that the integration of LPMs does not compromise the model's ability to generalize from data while providing meaningful insights into its decision-making processes. 

\paragraph{Enhancing editability with high stability.}

Another challenge lies in balancing model editability with stability. Editable models allow engineers and data scientists to adjust and refine model behavior to meet new requirements or eliminate undesired actions. However, frequent edits can lead to instability, potentially degrading the model's performance on previously generalized samples.

Compared to uneditable neural network methods, LPMs and editable machine learning models are poised to become new focal points~\cite{vojivr2020editable}. These models excel in interpretability and can quickly adapt to new needs and eliminate unwanted behaviors. They naturally represent relational data, making them suitable for downstream tasks involving such data. For instance, using neural network models directly for classification tasks on tabular data often yields performance that is inferior to decision tree and rule-based methods~\cite{popov2019neural,grinsztajn2022tree}. Moreover, their interpretability and editability are limited, hindering the quick and accurate incorporation of new rules.

By utilizing the rule extrapolation capabilities of LPMs~\cite{reizingerposition}, we can compensate for the shortcomings of these discriminative models. For example, \cite{nam2024optimized} employs large models to augment data for decision trees, enhancing their performance. From a practical standpoint, interpretable methods in tabular domains can be as accurate as black-box models. Researchers have leveraged interpretable machine learning to help practitioners identify defects in datasets, discover new scientific insights, and build fairer and more robust models~\cite{caruana2022data}.

Data analysts prefer white-box models, therefore, researchers in business, medicine, energy, and other fields have begun to combine LPMs with interpretable models~\cite{vertsel2024hybrid,gerussi2022llm,Zhang2024LargeLM}. These methods excel in editability, carefully integrating LPMs' reasoning capabilities with editable machine learning algorithms to enhance model generalization without compromising performance on existing generalized samples.


\subsection{LPMs Enhance Data Quality Optimization}\label{sec:data_quality}

Data quality is a critical factor in the success of machine learning models and data analysis. Poor data quality can lead to incorrect conclusions, model overfitting, and reduced generalization ability. Large Pretrained Models (LPMs) offer new avenues for enhancing data quality by addressing issues such as data incompleteness, uneven distribution, noise, and errors. By leveraging the strengths of LPMs in data generation, inference, and cleaning, we can improve the reliability and robustness of data analysis.

\subsubsection{Representative Data Sampling/Generating}

Representative sampling is essential to ensure that the data collected accurately reflects the underlying population or phenomenon. In the context of PAC learning, the distribution $\mathcal{D}$ from which the samples are drawn plays a crucial role in the learning process. If the sample does not represent $\mathcal{D}$ well, the learning algorithm $\mathcal{L}$ may not produce a hypothesis $h$ that approximates the true concept $c$ within the desired error bounds.

LPMs can assist in active representative sampling by identifying regions in the data space where additional samples would most improve the model's performance. By doing so, they help mitigate issues related to insufficient or uneven data distributions, which are common challenges in real-world applications. For instance, when certain classes are underrepresented, LPMs can guide the collection of additional samples for those classes, enhancing the overall representativeness of the dataset. \cite{Wang2023SoloDD} proposes SoloDD, which can perform data discovery on large-scale databases to find helpful records from a large dataset.

\paragraph{Generating with Deductive Bias.}

LPMs can generate synthetic data that adhere to known constraints and logical rules, a process we refer to as generating with deductive bias. Data generating involves generating representative entities and linkages according to these rules. 


For example, linkages would be missing in tabular data due to heterogeneity forms of the same entity. LPMs help to discover linkages to create more complete records to enhance semantic accuracy~\cite{Nobari2023DTTAE}. By leveraging prior knowledge and deductive reasoning, LPMs produce data that not only augment the existing dataset but also preserve essential properties and invariants of the data generation mechanism. This approach helps address data scarcity and imbalance by enriching the dataset with high-quality samples that reflect the underlying concepts more accurately.

Generative models like Variational Autoencoders (VAEs)~\cite{096kingma2013auto}, Generative Adversarial Networks (GANs)~\cite{095goodfellow2014generative}, and flow-based models~\cite{huamortizing} enable LPMs to create samples similar to the training data with reorganized causes and effect inferred by these inference techniques implied in the data. By enhancing the model's understanding of data distributions and algebraic structures, these generative methods improve generalization ability and robustness. For example, LPMs can generate data beneficial to analysis through adversarial generation~\cite{du2024enhancing,weng2023g}, effectively capturing global characteristics of the data.

Researchers have found that LPMs can enhance Bayesian inference and variational inference methods~\cite{huamortizing}. These methods infer important structures within the data and generate new data based on these structures, significantly improving the accuracy and reliability of data analysis in scientific research and industrial applications.

\subsubsection{Robustness Against Errors}

Robustness against errors is vital for the reliability of machine learning models. Errors in data, such as noise, missing values, and inconsistencies, can lead to overfitting and reduced model performance. In the PAC learning framework, robustness can be viewed as the ability of the learning algorithm $\mathcal{L}$ to produce a hypothesis $h$ that approximates the true concept $c$ even when the data distribution $\mathcal{D}$ contains errors.

\paragraph{Data Cleaning.}

LPMs play a significant role in data cleaning by detecting and correcting errors in datasets. They can identify data points that violate known data quality rules and constraints~\cite{li2024towards}, assisting analysts in cleaning the data effectively. By automating error detection and correction, LPMs improve the overall data quality, which is essential for reliable inductive reasoning as discussed earlier.

Data analysts face challenges in accurately and efficiently representing domain or expert knowledge using predictive models and domain-specific languages. The optimization of data quality is essentially about using limited data, combined with expert knowledge, to perform induction and deduction in the hypothesis space $\mathcal{H}$, continuously providing conservative rules closer to the data generation mechanism~\cite{peng2022self}. LPMs aid in this process by offering implicit representations of potentially unknown information, serving as a valuable starting point for data quality optimization.

\paragraph{Robust Methods.}

Developing robust hypothesis classes and learning algorithms is crucial for handling errors and noise in data. LPMs contribute to the creation of robust methods by enhancing the model's capacity to generalize from imperfect data. For example, LPMs can help in constructing hypothesis spaces that include invariants and constraints derived from algebraic~\cite{Miao2022LearningIA}, analytic~\cite{Neu2022GeneralizationBV}, and geometric methods~\cite{Atzeni2023InfusingLS}, which improve the model's generalization ability even when data quality is compromised.

Moreover, generative models have significant advantages in addressing data missing and uneven distribution issues. By learning the potential distribution of the data, generative models can generate new samples that better capture the global characteristics of the data~\cite{094dai2017good}. Studies have shown that in low-resource environments, the performance of generative models surpasses that of discriminative models~\cite{097yoon2017semi}. This is primarily because generative models can generate more high-quality training data to compensate for the lack of labeled data, thereby improving the model's generalization ability. Discriminative models, which rely directly on existing labeled data, cannot fully utilize the potential information in unlabeled data~\cite{102yang2018deep}.

By integrating LPMs into the data quality optimization process, we can enhance the robustness and reliability of machine learning models, ensuring that they perform effectively even in the presence of data imperfections. This aligns with the principles of PAC learning, where the goal is to learn approximately correct concepts from data distributions, and supports both inductive and deductive reasoning in the analysis.

\subsection{Automated Machine Learning}\label{sec:auto_ml}

Automated Machine Learning (AutoML) aims to automate the design, deployment, and optimization processes of machine learning models, enabling non-domain experts to effectively utilize data and reducing the need for manual intervention by professional data scientists. It includes model selection and optimization, feature engineering~\cite{Hollmann2023LargeLM}, hyperparameter tuning, model evaluation, and end-to-end process automation~\cite{salehin2024automl}. The following definition and insight highlight the importance of choosing appropriately represented sample distributions, learning algorithms, and hypothesis spaces.

\paragraph{Definition.} Given a sample size $m \geq \text{poly}(1/\epsilon, 1/ \delta, \text{size}(x), \text{size}(c))$, if a learning algorithm $\mathcal{L}$ makes the concept class $\mathcal{C}$ PAC identifiable, and the running time of $\mathcal{L}$ is a polynomial function $\text{poly}(1/\epsilon, 1/ \delta, \text{size}(x), \text{size}(c))$, then the concept class $\mathcal{C}$ is efficiently PAC learnable. Here, $\text{size}(x)$ and $\text{size}(c)$ represent the complexity or dimensionality of a single sample and a single concept, respectively.

\paragraph{Insight.} In machine learning, for the same concept class, choosing different representations, learning algorithms, and hypothesis spaces can lead to different learnability outcomes.



\subsubsection{Consolidating AutoML}

Automated Machine Learning (AutoML) aims to automate the design, deployment, and optimization processes of machine learning models, enabling non-domain experts to effectively utilize data and reducing the need for manual intervention by professional data scientists. However, constructing AutoML projects often requires significant manual effort in configuring pipelines, selecting appropriate algorithms, and tuning parameters. LPMs have shown promise in automating aspects of feature engineering (FE), neural architecture search (NAS), and hyperparameter optimization (HPO), scaling AutoML requires going beyond these components. 

In terms of PAC learning theory, the choice of representations (controlled by the form of selected feature), learning algorithms (partially tuned by hyperparameter), and hypothesis spaces (controlled by model architecture) significantly affect the learnability of a concept class $\mathcal{C}$. By utilizing LPMs to construct more expressive and adaptable hypothesis spaces $\mathcal{H}$, we can improve the efficiency of the learning algorithm $\mathcal{L}$, ensuring that the concept class $\mathcal{C}$ is efficiently PAC learnable. This reduces the manual effort in algorithm selection and hyperparameter tuning, as the LPMs can generalize across different contexts and data distributions.

Recent works have utilized LPMs to enhance these various aspects of AutoML. For instance,~\cite{Hollmann2023LargeLM} achieved automatic feature engineering based on large language models (LLMs), streamlining the process of extracting relevant features from data. Additionally,\cite{sayed2024gizaml} employed LPMs to explore neural architecture search and hyperparameter spaces for foundational learning and inference methods. These approaches leverage the capabilities of LPMs to navigate complex search spaces efficiently.

Large Pretrained Models (LPMs) have demonstrated great potential in automating model selection and optimization within the data analysis process~\cite{liu2023jarvix}. Recent studies have shown that LPMs can implement standard machine learning algorithms in different contexts, such as least squares regression and gradient descent for two-layer neural networks~\cite{bai2024transformers}. This suggests that LPMs can implicitly perform algorithm selection and optimization, reducing the manual effort required in constructing AutoML projects.



\subsubsection{Scaling AutoML}

In the context of PAC learning, scaling AutoML involves ensuring that the sample complexity and computational complexity remain acceptable, we can construct learning algorithms $\mathcal{L}$ that maintain efficiency while handling more complex hypothesis spaces $\mathcal{H}$ and larger concept classes $\mathcal{C}$. For example \cite{HuZWCM0WSXZCY0K24} proposes an open-ended data analysis agent, which composes more complex mathematical models. This is more complex than automated search in a fixed model space and constrained task to solve but it has more potential to help non-expert analysts or non-human-interference analytical tasks with open-ended goals. 

To move beyond FE, NAS, and HPO, future research should focus on incorporating LPMs into other stages of the machine learning pipeline, such as data augmentation, model ensembling, and transfer learning. This should involve more explicit management of logical knowledge which encodes consistent structural methods~\cite{SongY00024, HsuMTW23}, which is discussed more elaboratedly \S~\ref{sec:dsl}. This holistic integration can enhance the overall performance and scalability of AutoML systems, enabling them to handle a wider range of tasks and datasets with minimal human intervention.

The application of LPMs in context learning provides a new perspective for algorithm selection. Models like GPT-3 and BERT are capable of understanding and processing complex contextual information, and based on this, selecting appropriate algorithms~\cite{009brown2020language, EoTGE}. These models leverage simple underlying rules, and as pointed out by~\cite{reizingerposition}, LPMs exhibit near-saturated statistical generalization properties and possess certain rule extrapolation capabilities. This endows them with strong context learning abilities, enabling them to adaptively select and optimize algorithms. Moreover, these extrapolation rules can be explicitly expressed as formal languages by LPMs~\cite{cheng2022binding}, enhancing the interpretability of AutoML results.

Furthermore, transducing the knowledge searched during the AutoML process into understandable formats is facilitated by LPMs' ability to generate explanations and formal representations. This enhances the interpretability of the models and allows analysts to gain insights into the reasoning behind model selections and predictions.

\section{Challenges}

The rise of large pretrained models (LPMs), such as GPT-3 and DALL·E, has brought significant transformations to the field of data analysis. By integrating various structured and semi-structured data (relational data, time-series data, text, images, audio, etc.) and employing methods that allow for formal verification to mine invariants and relationships, they provide more comprehensive and complex data analysis capabilities. However, despite their immense potential in certain applications, there are still some shortcomings in their application to data analysis.

\paragraph{Optimization of Inference Costs.} The efficiency issue of large models is a significant challenge. These models typically require substantial computational resources for inference and training, leading to high costs and scalability difficulties in practical applications~\cite{041zhai2022scaling}. \cite{chow2024performance} studied the costs of large models, estimating that operating ChatGPT costs over \$700,000 per day, and small businesses using GPT-4 to support customer service may incur monthly costs exceeding \$21,000. The high infrastructure and financial costs, coupled with the need for specialized talent, make LLM technology unattainable for most organizations. Additionally, the upfront costs of using this technology include emissions from manufacturing the related hardware and the costs of running that hardware during training.

\paragraph{Domain Generalization Ability.} Therefore, rapidly adapting large models and consolidating their reasoning and learning capabilities has become an urgent problem to solve. Many pretrained models exhibit poor transferability between different tasks, requiring frequent adjustments and fine-tuning. Applying pretrained models to different datasets and tasks usually necessitates substantial reconfiguration, with a variety of methods including prompt engineering~\cite{sordoni2024joint}, retrieval-augmented generation (RAG)~\cite{gao2023retrieval}, fine-tuning, knowledge editing~\cite{Wang2023KnowledgeEF}, reinforcement learning~\cite{Kaufmann2023ASO}, and incremental learning~\cite{wu2024continual}. The rapid iteration of technology increases development and maintenance costs and affects the speed of initiating data analysis tasks. Although these technologies claim to achieve domain transfer of large models at lower costs, meticulous and tedious adjustments are still required for each new task. From a data analysis perspective, it is essential to discuss the principles for selecting domain transfer technologies, helping researchers clarify the use of these techniques to approach best practices.

\paragraph{Limitations of Consistency.} Moreover, these technologies have not currently solved the fundamental limitations of large models~\cite{bender2021dangers}. For example, issues of bias in large models, hallucinations~\cite{Ji2022SurveyOH}, lack of robustness to different forms of prompts~\cite{Lu2021FantasticallyOP}, and susceptibility to interference from irrelevant content in prompts and training data~\cite{Shi2023LargeLM}. Researchers should learn to coexist with these inherent limitations of large models when handling data analysis tasks. Similarly, from a data analysis perspective, providing a roadmap to understand and overcome these limitations is crucial.

\paragraph{Application of Fundamental Theories.} Knowledge being treated with disdain may be due to the maturity of the field; furthermore, pretrained models in data analysis often rely on new tools and techniques, which may lead to the neglect of the importance of traditional theories, constituting a risk of knowledge regression. For example, optimization theory and relational data models~\cite{codd2007relational} are core theories in data analysis. Therefore, it is necessary to use these foundational methods to mutually promote applications of large models~\cite{li2024can}. The relational data model has irreplaceable advantages in handling structured data, but in the application of multimodal models, it is often supplanted by more novel techniques, leading to a disconnect between theory and practical applications~\cite{dinh2024large}. To reduce data redundancy and anomalies, the relational dependency paradigm remains crucial, while large models often lack effective methods when dealing with these issues. Additionally, directly applying large models to a specific type of data and task is often undesirable~\cite{tan2024language}, indicating that large models are not a panacea for all problems.

\paragraph{Trust Issues.} Explainability aims to use large models to obtain trustworthy analytical conclusions and conservatively seek more optimized analytical methods. However, the reasoning of large models is accompanied by uncertainty and the inherent ambiguity of natural language. Therefore, seeking stronger functional dependencies, such as provable theorems or other logical forms, is essential~\cite{morishita2023learning,pei2023can,abbe2023generalization,yang2024leandojo}. Combining large models with traditional data analysis theories can enhance the reliability and interpretability of models~\cite{khakhar2023pac}. The integration of foundational data analysis methods with pretrained models can better solve complex data analysis problems.

Although large multimodal pretrained models have shown great potential in data analysis, issues such as their cost, maintainability, interpretability, robustness and reliability, and compatibility with foundational theories still need further resolution. These constitute significant challenges in further applying data mining to data analysis.




 \section{Future Research Outlook}

After a comprehensive examination of the current state of data analysis, future research directions can be envisioned from the following three dimensions.

\subsection{Further Deepening and Developing Existing Data Analysis Methods}

Future research will continue to deepen existing methods, including the further refinement of relational data models, adaptive improvements of decision tree algorithms for different data distributions, performance optimization of clustering analysis when handling large-scale datasets, innovation in artificial neural network architectures, and intelligent upgrades of automated machine learning technologies. Additionally, data augmentation methods based on rules or closed-domain data will be a research focus, aiming to enhance model generalization and adaptability to specific domain data.

\subsection{Data Analysis Methods Enhanced by Large Pretrained Models}

The introduction of large pretrained models (LMs) has brought new perspectives to data analysis. Future research will explore how to enhance models' understanding of complex data through knowledge-augmented neural networks and how to utilize generative open-domain data augmentation techniques to expand datasets and improve model generalization. Meanwhile, research on complex prediction and inference methods will assist in solving more intricate data analysis problems, such as time-series forecasting and causal inference.

\subsection{New Possibilities Brought by Large Pretrained Models}

LM technology will usher in a new chapter in data analysis. Researchers will explore automatic code generation and optimization techniques to reduce development time and improve code quality. Automatic goal planning, as well as automated mathematical discovery and theorem proving, may change how we solve complex problems. Multilevel modeling of complex systems will help us understand and predict system behaviors more comprehensively. Rapid domain adaptation and automatic intervention with counterfactual reasoning technologies will provide more precise support for decision-making.

With continuous technological advancements, future data analysis will become more intelligent and automated, capable of handling more complex data and problems. Researchers need to continuously explore new algorithms, models, and application scenarios to promote sustained development and innovation in the field of data analysis.

\section{Conclusion}

Through an in-depth literature review of data analysis, we recognize that large model technology plays an important role in systematically optimizing the data analysis process. These models, utilizing advanced techniques such as deep learning and neural networks, not only improve the efficiency of data processing but also enhance the ability to extract valuable information from data. Although large model technology is not indispensable, it has demonstrated significant advantages in handling large-scale and complex datasets, especially in data cleaning, feature extraction, and pattern recognition.

The personalized data analysis, the responsibility and antifragility of data analysis, and the promotion of real-time data analysis for decision-making that we mentioned all emphasize the critical role of data analysis technology in modern business. These research advancements indicate that data analysis technology is evolving toward greater intelligence and automation to adapt to the constantly changing business environment and market demands.

However, we also observe the challenges that large model technology faces in practical applications, including high computational resource consumption. These issues suggest that future research needs to find a balance between technological innovation and existing challenges to promote the sustainable development of data analysis technology.

We have also revealed the application prospects of large model technology in various fields, especially in business, finance, and healthcare. These application cases demonstrate that large model technology has the potential to greatly improve the quality and efficiency of decision-making. Future research will further explore the application effects of these models in specific domains and how to enhance their practicality and accuracy through continuous model optimization and iteration.

In summary, the future development of data analysis will be multifaceted, requiring comprehensive consideration of technological innovation, practical applications, ethical regulations, and social impact. Through a comprehensive analysis of existing literature, we have reason to believe that large model technology will continue to serve as an important driving force in the field of data analysis, promoting continuous progress and innovation in related technologies.


% 参考文献
% \nocite{*}
\printbibliography[heading=bibintoc, title=\ebibname]

\appendix
%\appendixpage
\addappheadtotoc

\end{document}
