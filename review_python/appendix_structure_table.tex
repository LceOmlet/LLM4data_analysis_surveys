
\begin{table}[ht]
    \centering
    \caption{论文结构}
    \label{tab:structure}
    \begin{tabular}{lllll}
    \toprule
\multirow{3}{*}{Related Work} & Representation Learning for Time Series &  &  &  \\
\cdashline{2-5}
 & Feature Transforms &  &  &  \\
\cdashline{2-5}
 & URL Based on Regularization and Multi-view Learning &  &  &  \\
\cdashline{1-5}
\multirow{4}{*}{Feature transforms} & Discrete Fourier Transform (DFT) &  &  &  \\
\cdashline{2-5}
 & Continuous wavelet transform (CWT) &  &  &  \\
\cdashline{2-5}
 & Encoding Time Series To Image &  &  &  \\
\cdashline{2-5}
 & Symbolic transform &  &  &  \\
\cdashline{1-5}
\multirow{2}{*}{Neural Encoder} & Convolutional Neural Network &  &  &  \\
\cdashline{2-5}
 & Transformer &  &  &  \\
\cdashline{1-5}
\multirow{8}{*}{Experiment Details} & \multirow{3}{*}{Experimental Settings} & Datasets &  &  \\
\cdashline{3-5}
 &  & Baselines &  &  \\
\cdashline{3-5}
 &  & Evaluation Metrics. &  &  \\
\cdashline{2-5}
 & Implementation Details. &  &  &  \\
\cdashline{2-5}
 & \multirow{4}{*}{Additional Research Questions} & What is the impact of data characteristics? &  &  \\
\cdashline{3-5}
 &  & How does the utilization of pretraining impact unsupervised time series representation learning compared to non-pre-trained models? &  &  \\
\cdashline{3-5}
 &  & Ablation (Ab) and leave one out (LOO) study. &  &  \\
\cdashline{3-5}
 &  & Sensitivity analysis for $\alpha$, $\beta$ and $\gamma$ in the trainin objective. &  &  \\
\cdashline{1-5}
\multirow{7}{*}{Proofs of Theories} & \textbf{Theorem}~\ref{the:seman_sim}: Equivalence Between Eigenvalues and Distance Reduction of Spectral Embeddings. &  &  &  \\
\cdashline{2-5}
 & \textbf{Theorem}~\ref{the:inv_est}: Multi-modal Invariance Estimation. &  &  &  \\
\cdashline{2-5}
 & \textbf{Theorem}~\ref{the:orth}: Orthogonality of Eigenfunction-Based Representations. &  &  &  \\
\cdashline{2-5}
 & \multirow{3}{*}{Spectral Selection Mechanism of Linearly Degenerated MMFA (LD-MMFA)} & \multirow{3}{*}{Brief Introduction to LD-MMFA and Unsupervised Objective.} & LD-MMFA Without Transform Alignment Recovers PCA. &  \\
\cdashline{4-5}
 &  &  & LD-MMFA Selects Spectral Consensus with Single Transformed Feature. &  \\
\cdashline{4-5}
 &  &  & Multiview Alignment via Joint Cross-Covariance Spectrum. &  \\
\cdashline{2-5}
 & Theorem~\ref{theorem:recover}: MMFA's recovery of KPCA and KCCA. &  &  &  \\
\cdashline{1-5}
\bottomrule
    \end{tabular}
\end{table}
