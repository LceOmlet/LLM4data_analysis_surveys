Kalai, A. T., & Vempala, S. S. (2024, June). Calibrated language models must hallucinate. In Proceedings of the 56th Annual ACM Symposium on Theory of Computing (pp. 160-171).
```
Proposes a lower bound for LM to hallusinate certain certain types of facts agnostic with the model architecture or data quality.
```

Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection
```
Prooved that for any big enough transformer there exists an ERM solution for recovering bayesian optimal stastical models in PAC style (i.e., ridge regression, two layer neural network etc.)
```

# 没有阅读的文章

1. xxx
2. yyy