1. 文章中的数据分析方法

### data wrangling:

#### Maybe magellan, https://sites.google.com/site/anhaidgroup/useful-stuff/the-magellan-data-repository

- ZeroED: Hybrid Zero-shot Error Detection through Large Language Model Reasoning. ICDE (2025)

- GIDCL: A Graph-Enhanced Interpretable Data Cleaning Framework with Large Language Models. Proc. ACM Manag. Data 2(6): 236:1-236:29 (2024)

- IterClean: An Iterative Data Cleaning Framework with Large Language Models, ACM-TURC '24

- Pool-Search-Demonstrate: Improving Data-wrangling LLMs via better in-context examples, NeurIPS 2023

- Tailoring the Shapley Value for In-Context Example Selection Towards Data Wrangling, ICDE 2025

- Towards Parameter-Efficient Automation of Data Wrangling Tasks with Prefix-Tuning, neurips 2022
<!-- SAGED: Few-Shot Meta Learning for Tabular Data Error Detection, EDBT, 2024 -->

- Efficient Mixture of Experts based on Large Language Models for Low-Resource Data Preprocessing, KDD, 24

- Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing, ACL, 24

- Table-GPT: Table Fine-tuned GPT for Diverse Table Tasks, SIGMOD, 24


#### others (ignore)

- DataVinci: Learning Syntactic and Semantic String Repairs, SIGMOD, 25

- An in-depth analysis of pre-trained embeddings for entity resolution, VLDBJ

- DATA LORE : can a large language model find all lost scrolls in a data repository?, 2024, ICDE

- Contextualized Data-Wrangling Code Generation in Computational Notebooks, ASE '24

- KnowTrans: Boosting Transferability of Data Preparation LLMs via Knowledge Augmentation, ICDE (2025)

2. 对于不同方法，哪些有着相同的benchmark

3. 整理成表格试试，一个benchmark可能需要一个